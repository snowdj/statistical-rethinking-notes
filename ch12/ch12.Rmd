# Chapter 12 - Monsters and Mixtures
```{r, include=FALSE}
library(rethinking)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

Chapter is about piecing together multiple statistical models. Three common cases, _over-dispersion_, _zero-inflated_ and _zero-augmented_, and _ordered categorical_.

## 12.1 - Over-dispersed counts 

Chapter 7 argued models based on normal distributions are overly sensitive to outliers, due to the thin Gaussian tail, also applies to count models.

Variance of a variable also called _dispersion_, when variance is more variable than the pure process, it's called _over-dispersion_.

_Continuous Mixture_ models - a linear model is attached to a distribution of observations.

### Beta-Binomial

_Beta-Binomial_ model assumes each binomial count observation has its own probability of success; estimates the distribution of probabilities across cases, instead of a single probability.

UC Berkeley example, has large variation. This model assumes that each has it's own, unique, unobserved probability of admission. Beta just makes the math easy because it's a conjugate prior.


The distribution
```{r}
pbar <- 0.5
theta <- 5
curve( dbeta2(x,pbar,theta) , from=0 , to=1 ,
    xlab="probability" , ylab="Density" )
```

The x-axis is probability values here, important to note.

Model below. Bind to $\bar{p}$ so changes in predictors change the central tendency.

\begin{align*}
  A_i &\sim \text{BetaBinomial}(N_i,\bar{p_i},\theta)\\
  \text{logit}(\bar{p_i}) &= \alpha_{\text{GID}[i]}\\
  \alpha_j &\sim \text{Normal}(0,1.5)\\
  \theta &= \phi + 2\\
  \phi &\sim \text{Exponential}(1)
\end{align*}

The variables: $A$ is outcome (```admit```), $N$ is number of applications, $\text{GID}[i]$ is gender id. 

The priors have a trick - assume dispersion of at least 2, flat. Less piles up on 0 and 1, more is increasingly heaped on a value. So we force that and add an exponential distribution

```{r, results=FALSE, message=FALSE, warning=FALSE}
library(rethinking)
data(UCBadmit)
d <- UCBadmit
d$gid <- ifelse( d$applicant.gender=="male" , 1L , 2L )
dat <- list( A=d$admit , N=d$applications , gid=d$gid )
m12.1 <- ulam(
    alist(
        A ~ dbetabinom( N , pbar , theta ),
        logit(pbar) <- a[gid],
        a[gid] ~ dnorm( 0 , 1.5 ),
        transpars> theta <<- phi + 2.0,
        phi ~ dexp(1)
    ), data=dat , chains=2 ,cmdstan = TRUE)
```

There's some interesting things with that model, transforming parameters of theta, so looking at the stan code:

```{r}
stancode(m12.1)
```

```{r}
  post <- extract.samples( m12.1 )
  post$da <- post$a[,1] - post$a[,2]
  precis( post , depth=2 )
```


Parameter ```a[1]``` is log-odds of admission for males, lower than ```a[2]```, text gives -0.45 and -0.34 respectively. Difference between the two is given by ```da```, which is highly uncertain -0.11.

Remember before there was a confounding - it appeared female admission was lower until the department predictor was added. That doesn't happen here since each row has its own unobserved intercept, sampled from a beta distribution with mean $\bar{p_i}$ and dispersion $\theta$

```{r}
gid <- 2
# draw posterior mean beta distribution
curve( dbeta2(x,mean(logistic(post$a[,gid])),mean(post$theta)) , from=0 , to=1 ,
    ylab="Density" , xlab="probability admit", ylim=c(0,3) , lwd=2 )

# draw 50 beta distributions sampled from posterior
for ( i in 1:50 ) {
    p <- logistic( post$a[i,gid] )
    theta <- post$theta[i]
    curve( dbeta2(x,p,theta) , add=TRUE , col=col.alpha("black",0.2) )
}
mtext( "distribution of female admission rates" )
```

Note the high degree of variation. Checking the posterior:

```{r}
postcheck( m12.1 )
```


Raw data is blue, 89% interval is between the $+$ signs. Model doesn't see departments, but does see heterogeneity across rows and uses the beta distribution to estimate it.

### Negative-Binomial or Gamma-Poisson

_Negative-Binomial_ or _Gamma-Poisson_ assumes each Poisson count observation has its own rate. Two parameters, mean (rate) and dispersion (scale)

$$
y_i \sim \text{Gamma-Poisson}(\lambda_i,\phi)
$$

The variance of Gamma-Poisson is $\lambda + \lambda^2 / \phi$, larger $\phi$ gets more similar to pure Poisson.

Going back to Oceanic tools dataset, we can make the outlier of Hawaii less influential by using Gamma-Poisson:

```{r, results=FALSE, message=FALSE, warning=FALSE}
library(rethinking)
data(Kline)
d <- Kline
d$P <- standardize( log(d$population) )
d$contact_id <- ifelse( d$contact=="high" , 2L , 1L )

dat2 <- list(
    T = d$total_tools,
    P = d$population,
    cid = d$contact_id )

m12.2 <- ulam(
    alist(
        T ~ dgampois( lambda , phi ),
        lambda <- exp(a[cid])*P^b[cid] / g,
        a[cid] ~ dnorm(1,1),
        b[cid] ~ dexp(1),
        g ~ dexp(1),
        phi ~ dexp(1)
    ), data=dat2 , chains=2, log_lik=TRUE , cmdstan = TRUE)
```

### Over-dispersion, entropy, information criteria

Both beta-binomial and gamma-Poisson are maximum entropy distributions, just try to account for unobserved heterogeneity. They're harder to fit, but still conceptually transparent. 

Don't use WAIC and PSIS (unless you're very sure). Ordinary binomial and Poisson models can be aggregated and disaggregated across rows without changing causal assumptions, not true of beta-binomial and gamma-Poisson.

Once you include over-dispersion in multilevel models, the obstacle is reduced, this is for next chapter.

## 12.2 - Zero-Inflated Outcomes

Often, things are not emissions from any pure process, but a mixture - we can use a _mixture model_, which use more than one likelihood for the same outcome variable.

Count variables are especially prone, particularly w.r.t. zeros.

### Zero-Inflated Poisson

Going back to dataset of monks copying manuscripts, this is binomial. But zero can arise from monks taking breaks on some days, but also in normal workdays as well.

$p$ is probability they take a break, always yielding a zero, $p-1$ is probability they work, sometimes yielding 0 and sometimes more than 0. 

\begin{align*}
  \text{Pr}(0|p,\lambda) &= \text{Pr}(\text{break}|p) + \text{Pr}(\text{work}|p) \times \text{PR}(0|\lambda)\\
  &= p + (1-p)\exp(-\lambda)
\end{align*}

Subsequently, 

$$
  \text{Pr}(y|y>0,p,\lambda) = \text{Pr}(\text{break}|p)(0) + \text{Pr}(\text{work}|p) \text{Pr}(y|\lambda) = (1-p)\frac{\lambda^y \exp(-\lambda)}{y!}
$$

Therefore we want the following model:

\begin{align*}
y_i &\sim \text{ZIPoisson}(p_i,\lambda_i)\\
\text{logit}(p_i) &= \alpha_p + \beta_p x_i\\
\log(\lambda_i) &= \alpha_\lambda + \beta_\lambda x_i
\end{align*}

Two linear models, two link functions, one for each process.

Generating the data and plotting:

```{r}
# define parameters
prob_drink <- 0.2 # 20% of days
rate_work <- 1    # average 1 manuscript per day

# sample one year of production
N <- 365

# simulate days monks drink
set.seed(365)
drink <- rbinom( N , 1 , prob_drink )

# simulate manuscripts completed
y <- (1-drink)*rpois( N , rate_work )

simplehist( y , xlab="manuscripts completed" , lwd=4 )
zeros_drink <- sum(drink)
zeros_work <- sum(y==0 & drink==0)
zeros_total <- sum(y==0)
lines( c(0,0) , c(zeros_work,zeros_total) , lwd=4 , col=rangi2 )
```


Building the model (giving it a slight prior nudge, assuming monks work more than break):

```{r, results=FALSE, message=FALSE, warning=FALSE}
m12.3 <- ulam(
    alist(
        y ~ dzipois( p , lambda ),
        logit(p) <- ap,
        log(lambda) <- al,
        ap ~ dnorm( -1.5 , 1 ),
        al ~ dnorm( 1 , 0.5 )
    ) , data=list(y=y) , chains=2, cmdstan=TRUE)
```

Probably another case where it's useful to look under the hood:

```{r}
stancode(m12.3)
```

Extracting samples and reverting back to natural scales:

```{r}
post <- extract.samples( m12.3 )
mean( inv_logit( post$ap ) ) # probability drink
mean( exp( post$al ) )       # rate finish manuscripts, when not drinking
```

This gives us values for $p$, the probability of them drinking, and then the rate of production when they do work. Cannot say for sure which day, but can understand rates.

## 12.3 - Ordered Categorical Outcomes

Common to have ordered categories, leveled along a dimension - on a scale of 1 to 7 how much do you like a food. The result is _ordered categories_ - different from count because differences are not necessarily equal.

In principle just a multinomial prediction, but ordering adds a constraint - predictions move in progression. Use a _cumulative link_ function - gives the probability that a value is that value or any smaller value.

### Moral intuition

Using data from philosophers and the trolley problem, asking "how morally permissible is it for an actor to pull the lever." Second problem changes it and says pulling the lever drops someone on the tracks (rather than switching tracks), which slows the trolley and saves 5 lives. Study how much worse people find the second than the first.

```{r}
library(rethinking) 
data(Trolley)
d <- Trolley
simplehist(d$response, xlim=c(1,7), xlab="response")
```

1-7 here is "how morally permissible the act is."

### Describing an ordered distribution with intercepts

Want to redescribe the histogram on a log-cumulative-odds scale - the cumulative analog of the logit link (logit is log-odds, cumulative logit is log-cumulative-odds).

```{r}
# discrete proportion of each response value
pr_k <- table( d$response ) / nrow(d)

# cumsum converts to cumulative proportions
cum_pr_k <- cumsum( pr_k )

# plot
plot( 1:7 , cum_pr_k , type="b" , xlab="response" ,
ylab="cumulative proportion" , ylim=c(0,1) )
```


Code above has changed it to the cumulative probabilities.

Next want the log-cumulative odds that a response value $y_i$ is equal-to-or-less-than some outcome $k$,

$$
\log \frac{\Pr(y_i) \leq k}{1-\Pr(y_i \leq k)} = \alpha_k
$$
with $\alpha_k$ being a unique intercept to each possible outcome value.

```{r}
logit <- function(x) log(x/(1-x)) # convenience function
round( lco <- logit( cum_pr_k ) , 2 )
```

(Note last one is infinity because $\log(1/(1-1)) = \infty$)

Really want posterior distribution of $\alpha_k$. Observing $k$, we can get likelihood by subtraction:

$$
p_k = \Pr (y_i = k) = \Pr (y_i \leq k) - \Pr (y_i \leq k-1)
$$

In model form - two ways of expressing:

One, used in the text:

\begin{align*}
  R_i &\sim \text{Ordered-logit}(\phi_i, \kappa)\\
  \phi_i &= 0\\
  \kappa_k &\sim \text{Normal}(0,1.5)
\end{align*}

The first line is the probability, the second is the linear model, the third is the common prior for each intercept.

The other, more literal, expression:

\begin{align*}
  R_i &\sim \text{Categorical}(\mathbf{p})\\
  p_1 &= q_1\\
  p_k &= q_k-q_{k-1}  \text{ for } K>k>1\\
  p_K &= 1 - q_{k-1}\\
  \text{logit}(q_k) &= \kappa_k - \phi_i\\
  \phi_i &= \text{terms of linear model}\\
  \kappa_k &\sim \text{Normal(0,1.5)}
\end{align*}

The first is the probability of data, the second through 4th lines are the probabilities of each $k$, the 5th is the cumulative logit link, the 6th is the linear model, and the last is the common priors. This is brutal but exposes that it's just a categorical distribution.

Fitting the basic model with no predictors:

```{r, results=FALSE, message=FALSE, warning=FALSE}
m12.4 <- ulam(
    alist(
        R ~ dordlogit( 0 , cutpoints ), # zero is placeholder for linear model
        cutpoints ~ dnorm( 0 , 1.5 )
    ) , data=list( R=d$response ), chains=2 , cores=4 ,cmdstan=TRUE)
```

Can also construct in quap:

```
m12.4q <- quap(
    alist(
        response ~ dordlogit( 0 , c(a1,a2,a3,a4,a5,a6) ),
        c(a1,a2,a3,a4,a5,a6) ~ dnorm( 0 , 1.5 )
    ) , data=d , start=list(a1=-2,a2=-1,a3=0,a4=1,a5=2,a6=2.5) )
```

Looking at posterior:
```{r}
precis( m12.4 , depth=2 )
```

And getting back the cumulative probabilities:
```{r}
round( inv_logit(coef(m12.4)) , 3 )
```


### Adding predictors

To include predictors, define the log-cumulative-odds of each response $k$ as a sum of intercept $\alpha_k$ and a linear model. For predictor $x$, this looks like $\phi_i = \beta x_i$. This makes the cumulative logit:

\begin{align*}
  \log \frac{ \Pr (y_i \leq k)}{1- \Pr (y_i \leq k)} &= \alpha_k - \phi_i``
  \phi_i &= \beta x_i
\end{align*}

Automatically ensures correct ordering of outcomes.

Turning back to the "trolley" problem, predictor variables are ```action```, ```intention```, and ```contact```:

1. No action, contact, or intention 
2. Action
3. Contact
4. Intention
5. Action and intention 
6. Contact and intention

The log-cumulative-odds of each response is now:

\begin{align*}
  \log \frac{\Pr (y_i \leq k)}{1-\Pr(y_i \leq k)} &= \alpha_k - \phi_i
  \phi_i &= \beta_A A_i + \beta_C C_i + B_{I,i} I_i\\
  B_{I,i} &= \beta_I + \beta_{IA} A_i + \beta_IC C_i
\end{align*}

$A_i$ is action on row $i$, $I_i$ is intention, $C_i$ is contact. Creating a model:

```{r, results=FALSE, message=FALSE, warning=FALSE}
dat <- list(
    R = d$response,
    A = d$action,
    I = d$intention,
    C = d$contact )
m12.5 <- ulam(
    alist(
        R ~ dordlogit( phi , cutpoints ),
        phi <- bA*A + bC*C + BI*I ,
        BI <- bI + bIA*A + bIC*C ,
        c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ),
        cutpoints ~ dnorm( 0 , 1.5 )
    ) , data=dat , chains=4 , cores=4 )

plot( precis(m12.5) , xlim=c(-1.4,0) )
```

Each slope is reliably negative. Intention and contact is the worst, but the other two individually don't have a large impact. Easier to plot the posterior predictions

```{r}
plot( NULL , type="n" , xlab="intention" , ylab="probability" ,
    xlim=c(0,1) , ylim=c(0,1) , xaxp=c(0,1,1) , yaxp=c(0,1,2) )


kA <- 0     # value for action
kC <- 0     # value for contact
kI <- 0:1   # values of intention to calculate over
pdat <- data.frame(A=kA,C=kC,I=kI)
phi <- link( m12.5 , data=pdat )$phi

## R code 12.28
post <- extract.samples( m12.5 )
for ( s in 1:50 ) {
    pk <- pordlogit( 1:6 , phi[s,] , post$cutpoints[s,] )
    for ( i in 1:6 ) lines( kI , pk[,i] , col=grau(0.1) )
}
```

Here y-axis is CDF and x-axis is a predictor variable. Again, you can do this for kA and kC to make a triptych plot. 

Also you can make a implied histogram of outcomes, use sim to simulate posteriors.

```{r}
kA <- 0     # value for action
kC <- 1     # value for contact
kI <- 0:1   # values of intention to calculate over
pdat <- data.frame(A=kA,C=kC,I=kI)
s <- sim( m12.5 , data=pdat )
simplehist( s , xlab="response" )
```


## 12.4 - Ordered Categorical Predictors

Now what about ordered predictors? Can also do that, go back to trolley problem and use level of education

```{r}
library(rethinking)
data(Trolley)
d <- Trolley
levels(d$edu)
```

8 levels, map to a vector in the correct order

```{r}
edu_levels <- c( 6 , 1 , 8 , 4 , 7 , 2 , 5 , 3 )
d$edu_new <- edu_levels[ d$edu ]
```

Each step has own marginal effect on the outcome, want to infer each effect - need 7 parameters for 8 levels. Add to the model:

$$
\phi_i = \delta_1 + \text{other linear model terms}
$$

for $\delta_1$ being the effect by moving from elementary to middle school. Then you chain on $\delta_2$ if finished middle school, so on and so forth until

$$
\phi_i = \beta_E \sum_{j=1}^{E_i-1}\delta_j + \text{other linear model terms}
$$

Now we've called $\beta_E$ the maximum sum (1) and $\delta$'s are fractions of it. $E_i$ is completed education level. This also helps define priors. The full model:

\begin{align*}
  R_i &\sim \text{Ordered-logit}(\phi_i,\kappa)\\
  \phi_i &= \beta_E \sum_{j=1}^{E_i-1}\delta_j + \beta_A A_I + \beta_I I_i + \beta_C C_i\\
  \kappa_k &\sim \text{Normal}(0,1.5)\\
  \beta_A, \beta_I, \beta_C, \beta_E &\sim \text{Normal}(0,1)\\
  \delta &\sim \text{Dirichlet}(\alpha)
\end{align*}

The _Dirichlet distribution_ is the multivariate extension of the beta distribution, parameterized by pseudo-counts of observations like the beta, just a long vector of them. Prior used is weak, simulating from it:

```{r,echo=FALSE}
library(gtools)
```

```{r}
set.seed(1805)
delta <- rdirichlet( 10 , alpha=rep(2,7) )
#str(delta)

h <- 3
plot( NULL , xlim=c(1,7) , ylim=c(0,0.4) , xlab="index" , ylab="probability" )
for ( i in 1:nrow(delta) ) lines( 1:7 , delta[i,] , type="b" ,
    pch=ifelse(i==h,16,1) , lwd=ifelse(i==h,4,1.5) ,
    col=ifelse(i==h,"black",col.alpha("black",0.7)) )
```

10 vectors of 7 probabilities, arbitrary one highlighted to show variation in a single vector. Building the model:

```{r, results=FALSE, message=FALSE, warning=FALSE}
dat <- list(
    R = d$response ,
    action = d$action,
    intention = d$intention,
    contact = d$contact,
    E = as.integer( d$edu_new ),   # edu_new as an index
    alpha = rep( 2 , 7 ) )      # delta prior

m12.6 <- ulam(
    alist(
        R ~ ordered_logistic( phi , kappa ),
        phi <- bE*sum( delta_j[1:E] ) + bA*action + bI*intention + bC*contact,
        kappa ~ normal( 0 , 1.5 ),
        c(bA,bI,bC,bE) ~ normal( 0 , 1 ),
        vector[8]: delta_j <<- append_row( 0 , delta ),
        simplex[7]: delta ~ dirichlet( alpha )
    ), data=dat , chains=2, cores=2)
```

Data list contains alpha prior - passed as "data" but really just definition of Dirichlet prior. To sum over $\delta$, contains ```bE*sum( delta_j[1:E])```, then uses <<- to append actual delta vector onto a zero. Last, $\delta$ parameters must sum to one, called a _simplex_, given by stan. This takes a long time, 20 minutes for 4 threads on 4 cores.

Looking at the stan code for that model:
```{r}
stancode{m12.6}
```

```{r}
precis( m12.6 , depth=2 , omit="kappa" )
```

Overall association of ```bE``` is negative $\rightarrow$ more educated individuals disapproved more of everything. Association smaller than treatment effects - most educated disapprove by about -0.3, while adding action reduces approval by -0.7, don't think causally yet since not randomized treatment.

Looking at multivariate distribution:

```{r}
delta_labels <- c("Elem","MidSch","SHS","HSG","SCol","Bach","Mast","Grad")
pairs( m12.6 , pars="delta" , labels=delta_labels )
```

All are negatively correlated, result of the sum to 1. Modest effect from all except "Some College" (SCol), which is marginal.

Instructive to compare against a more conventional model with education as a ordinary continuous variable:

```{r}
dat$edu_norm <- normalize( d$edu_new )
m12.7 <- ulam(
    alist(
        R ~ ordered_logistic( mu , cutpoints ),
        mu <- bE*edu_norm + bA*action + bI*intention + bC*contact,
        c(bA,bI,bC,bE) ~ normal( 0 , 1 ),
        cutpoints ~ normal( 0 , 1.5 )
    ), data=dat , chains=4 , cores=4 )
precis( m12.7 )
```

Very low association from education to rating - effect isn't linear. 

Showed ordered predictors - from a causal perspective we might still have concerns weather association is spurious, since correlated with age, which will go over in the problems for this section

## 12.5 - Summary

This chapter went over generalizations of GLMs. 

- Ordered logisitics, good for categorical outcomes with ordering
- Zero-inflated models, mixutre models accounting for excess of 0's
- Over-dispersion models, such as beta-binomial and gamma-Poisson, change shape as a function of a linear model

Next chapter, we generalize even furtehr by doing multilevel modeling.
